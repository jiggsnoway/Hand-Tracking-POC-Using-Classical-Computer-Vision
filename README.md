# Hand Tracking POC ðŸ‘‹

A real-time hand tracking system using classical computer vision techniques to detect hand proximity to virtual boundaries and trigger safety warnings.

## ðŸ“‹ Overview

This Proof of Concept (POC) demonstrates real-time hand/fingertip tracking using a camera feed to detect when a user's hand approaches a virtual object on screen. The system classifies interactions into three states (SAFE, WARNING, DANGER) and displays appropriate visual feedback.

**Developed as part of:** Machine Learning Internship Assignment  
**Company:** Arvyax Technologies  
**Submission Date:** December 2025

## âœ¨ Features

- âœ… Real-time hand tracking without pre-built pose detection APIs
- âœ… Distance-based state classification (SAFE/WARNING/DANGER)
- âœ… Visual feedback with color-coded warnings
- âœ… "DANGER DANGER" alert when hand crosses boundary
- âœ… High performance: 30+ FPS on CPU-only execution
- âœ… Uses classical computer vision techniques (no MediaPipe/OpenPose)

## ðŸŽ¯ Objectives Met

- [x] Real-time hand position tracking via camera feed
- [x] Virtual boundary drawn on screen
- [x] Distance-based state logic
- [x] Clear on-screen warning system
- [x] Performance: 30 FPS (exceeds 8 FPS requirement)
- [x] Classical CV techniques (color segmentation, contours)

## ðŸ› ï¸ Technical Approach

### Detection Method
- **Color Space:** HSV (Hue, Saturation, Value)
- **Technique:** Skin color segmentation
- **Tracking:** Contour detection and centroid calculation
- **Distance Metric:** Euclidean distance in pixel space

### State Classification Logic
```
SAFE    â†’ Distance > 100 pixels from boundary
WARNING â†’ Distance 50-100 pixels from boundary  
DANGER  â†’ Distance < 50 pixels from boundary
```

### Pipeline
```
Camera Feed â†’ Preprocessing â†’ Skin Detection â†’ 
Contour Extraction â†’ Centroid Calculation â†’ 
Distance Measurement â†’ State Classification â†’ 
Visual Overlay â†’ Display
```

## ðŸ“¦ Installation

### Prerequisites
- Python 3.7 or higher
- Webcam
- pip (Python package manager)

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/jiggsnoway/hand_tracking.git
cd hand_tracking
```

2. **Create virtual environment** (recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ðŸš€ Usage

### Run the application
```bash
python hand_tracking.py
```

### Controls
- **'q'** - Quit the application
- The system will open two windows:
  - Main tracking window with state visualization
  - Debug window showing hand mask

### Testing the System
1. Position yourself in front of the camera
2. Move your hand horizontally toward the red vertical line
3. Observe state changes:
   - Far from line â†’ **GREEN** (SAFE)
   - Approaching line â†’ **ORANGE** (WARNING)
   - Near/crossing line â†’ **RED** (DANGER) + "DANGER DANGER" text

## ðŸ“Š Performance Results

| Metric | Target | Achieved | Status |
|--------|--------|----------|--------|
| FPS | â‰¥8 | 30+ | âœ… Exceeded |
| Detection | Real-time | Yes | âœ… |
| State Accuracy | High | High | âœ… |
| CPU Usage | Efficient | Low | âœ… |

### Sample Output
```
Frame: 30  | FPS: 31.5 | State: SAFE    | Distance: 301px
Frame: 60  | FPS: 30.2 | State: WARNING | Distance: 52px
Frame: 90  | FPS: 30.2 | State: DANGER  | Distance: 20px
```

## ðŸ“ Project Structure

```
hand-tracking-poc/
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ hand_tracking.py        # Main application code
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ docs/                  # Additional documentation
â”‚   â”œâ”€â”€ APPROACH.md        # Detailed technical approach
â”‚   â””â”€â”€ LIMITATIONS.md     # Known limitations

```

## ðŸ”§ Configuration

You can adjust detection parameters in `config.py` or directly in the code:

```python
# HSV skin color range
LOWER_SKIN = np.array([0, 20, 70], dtype=np.uint8)
UPPER_SKIN = np.array([20, 255, 255], dtype=np.uint8)

# Distance thresholds (pixels)
SAFE_DISTANCE = 100
WARNING_DISTANCE = 50
DANGER_DISTANCE = 50

# Boundary position
BOUNDARY_X = 320  # Center of 640px width
```

## âš ï¸ Limitations

### Known Issues
1. **Skin Detection:** Detects all skin-colored regions (face, arms, hands)
2. **Lighting Sensitivity:** Performance varies with lighting conditions
3. **Single Object:** Tracks only the largest detected contour
4. **2D Distance:** Measures distance in pixel space, not true 3D depth

See [docs/LIMITATIONS.md](docs/LIMITATIONS.md) for detailed analysis and potential solutions.

## ðŸ”® Future Enhancements

- [ ] Implement background subtraction for better hand isolation
- [ ] Add Region-of-Interest (ROI) filtering
- [ ] Support for YCrCb color space (better lighting invariance)
- [ ] Multi-hand tracking capability
- [ ] Depth estimation using hand size
- [ ] ML-based hand segmentation for improved accuracy
- [ ] Audio alerts in addition to visual warnings
- [ ] Configuration GUI for threshold adjustment

## ðŸ§ª Testing

### Optimal Conditions
- âœ… Good lighting (natural or bright artificial light)
- âœ… Plain, non-skin-colored background
- âœ… Camera positioned to capture hand clearly
- âœ… Hand as the largest skin-colored object in frame

### Testing Checklist
- [ ] Hand moves from left to right â†’ States change correctly
- [ ] Hand approaches boundary â†’ WARNING triggered
- [ ] Hand crosses boundary â†’ DANGER displayed
- [ ] No hand in frame â†’ Shows "No hand detected"
- [ ] FPS counter shows 20+ FPS consistently

## ðŸ“š Documentation

- **Detailed Approach:** [docs/APPROACH.md](docs/APPROACH.md)
- **Limitations & Solutions:** [docs/LIMITATIONS.md](docs/LIMITATIONS.md)

## ðŸ¤ Contributing

This is a POC for an internship assignment. Not accepting contributions at this time.

## ðŸ“„ License

This project is for educational and demonstration purposes.

## ðŸ‘¤ Author

**[Jigyashman Hazarika]**
- Email: jiggsnoway18@gmail.com
- GitHub: (https://github.com/jiggsnoway)
- LinkedIn: [Jigyashman Hazarika](https://linkedin.com/in/yourprofile)

## ðŸ™ Acknowledgments

- Assignment provided by Arvyax Technologies
- Guidance from Shalabh Bhatnagar
- OpenCV community for excellent documentation

## ðŸ“ž Contact

For questions or feedback about this POC:
- Email: jiggsnoway18@gmail.com
- Assignment Context: Machine Learning Internship - Arvyax Technologies

---

**Note:** This is a Proof of Concept demonstrating feasibility. For production deployment, additional robustness, error handling, and testing would be required.

**Submission Deadline:** December 7, 2025